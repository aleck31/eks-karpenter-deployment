# EKS GPU æ”¯æŒéƒ¨ç½²æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—å¸®åŠ©åœ¨ç°æœ‰ EKS + Karpenter é›†ç¾¤åŸºç¡€ä¸Šæ·»åŠ  GPU æ”¯æŒï¼Œç”¨äºæœºå™¨å­¦ä¹ å·¥ä½œè´Ÿè½½ã€‚

## ğŸ¯ GPU æ¶æ„è®¾è®¡

### æŠ€æœ¯æ ˆ
- **AMI**: Deep Learning OSS Nvidia Driver AMI (AL2023)
- **GPU å®ä¾‹**: G4dn, G5, G6, G6e, P3, P4 ç­‰ç³»åˆ—
- **å®¹å™¨è¿è¡Œæ—¶**: containerd + nvidia-container-runtime
- **è®¾å¤‡æ’ä»¶**: NVIDIA Device Plugin
- **è°ƒåº¦ç­–ç•¥**: Taint/Toleration + NodeSelector

### æ¶æ„åŸåˆ™
1. **ä¸“ç”¨èŠ‚ç‚¹æ± ** - GPU èŠ‚ç‚¹ç‹¬ç«‹ç®¡ç†
2. **æ±¡ç‚¹éš”ç¦»** - é˜²æ­¢é GPU å·¥ä½œè´Ÿè½½è°ƒåº¦
3. **æˆæœ¬ä¼˜åŒ–** - æ”¯æŒ Spot å®ä¾‹
4. **è‡ªåŠ¨æ‰©ç¼©å®¹** - åŸºäºå·¥ä½œè´Ÿè½½éœ€æ±‚

## ğŸš€ éƒ¨ç½²æ­¥éª¤

### 1. éƒ¨ç½² GPU NodePool

```bash
# åº”ç”¨ GPU NodePool é…ç½®
kubectl apply -f gpu/nodepool-gpu.yaml

# éªŒè¯ NodePool åˆ›å»º
kubectl get nodepool nodepool-gpu
kubectl get ec2nodeclass nodeclass-gpu
```

### 2. éƒ¨ç½² NVIDIA Device Plugin

NVIDIA Device Plugin è´Ÿè´£ GPU èµ„æºçš„å‘ç°ã€åˆ†é…å’Œç®¡ç†ï¼Œæ˜¯ç”Ÿäº§ç¯å¢ƒçš„å¿…éœ€ç»„ä»¶ã€‚
**Device Plugin åŠŸèƒ½**:
- **GPU èµ„æºå‘ç°**: è‡ªåŠ¨è¯†åˆ«èŠ‚ç‚¹ä¸Šçš„ GPU è®¾å¤‡
- **èµ„æºå¹¿å‘Š**: å‘ Kubernetes API æŠ¥å‘Š `nvidia.com/gpu` èµ„æº
- **è®¾å¤‡åˆ†é…**: ä¸º Pod åˆ†é…ä¸“ç”¨ GPU è®¾å¤‡
- **èµ„æºéš”ç¦»**: é˜²æ­¢å¤šä¸ª Pod äº‰æŠ¢åŒä¸€ GPU

#### éƒ¨ç½²å®˜æ–¹ NVIDIA Device Plugin
```bash
kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.16.2/deployments/static/nvidia-device-plugin.yml
```

#### éªŒè¯ Device Plugin éƒ¨ç½²çŠ¶æ€
```bash
kubectl get daemonset -n kube-system nvidia-device-plugin-daemonset

# output:
NAME                             DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
nvidia-device-plugin-daemonset   1         1         1       1            1           <none>          2m
```

#### æ£€æŸ¥ Device Plugin Pod è¿è¡ŒçŠ¶æ€
```bash
kubectl get pods -n kube-system -l name=nvidia-device-plugin-ds

# output:
NAME                                   READY   STATUS    RESTARTS   AGE
nvidia-device-plugin-daemonset-xxxxx   1/1     Running   0          2m
```

### 3. éªŒè¯ GPU èŠ‚ç‚¹

```bash
# ç­‰å¾… GPU èŠ‚ç‚¹å¯åŠ¨ (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)
kubectl get nodes -l node-type=gpu

# æ£€æŸ¥èŠ‚ç‚¹ GPU èµ„æº
kubectl describe node <gpu-node-name> | grep nvidia.com/gpu
```

## ğŸ§ª æµ‹è¯• GPU åŠŸèƒ½

### éƒ¨ç½²æµ‹è¯• Pod

```bash
## ğŸ§ª æµ‹è¯• GPU åŠŸèƒ½

### æ–¹å¼1: æ ‡å‡† GPU èµ„æºè¯·æ±‚ (æ¨è)

```bash
# éƒ¨ç½²æ ‡å‡† GPU æµ‹è¯• Pod (ä½¿ç”¨ nvidia.com/gpu èµ„æº)
kubectl apply -f tests/test-gpu-standard.yaml

# æŸ¥çœ‹æµ‹è¯•ç»“æœ
kubectl logs gpu-standard-test
```

### æ–¹å¼2: NodeSelector è°ƒåº¦ (å…¼å®¹æ–¹å¼)

```bash
# éƒ¨ç½² NodeSelector æ–¹å¼çš„ GPU æµ‹è¯• Pod
kubectl apply -f tests/test-gpu-workload.yaml

# æŸ¥çœ‹æµ‹è¯•ç»“æœ
kubectl logs gpu-test-pod
```

### é¢„æœŸè¾“å‡º
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |
| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
```

## ğŸ“‹ GPU å®ä¾‹ç±»å‹é€‰æ‹©

### G4dn ç³»åˆ— (NVIDIA T4)
- **é€‚ç”¨åœºæ™¯**: æ¨ç†ã€è½»é‡è®­ç»ƒ
- **æ€§ä»·æ¯”**: é«˜
- **æ¨èç”¨é€”**: æ¨¡å‹æ¨ç†ã€å¼€å‘æµ‹è¯•

| å®ä¾‹ç±»å‹ | GPU | vCPU | å†…å­˜ | ç½‘ç»œæ€§èƒ½ |
|---------|-----|------|------|----------|
| g4dn.xlarge | 1x T4 | 4 | 16 GB | æœ€é«˜ 25 Gbps |
| g4dn.2xlarge | 1x T4 | 8 | 32 GB | æœ€é«˜ 25 Gbps |
| g4dn.4xlarge | 1x T4 | 16 | 64 GB | æœ€é«˜ 25 Gbps |

### G5 ç³»åˆ— (NVIDIA A10G)
- **é€‚ç”¨åœºæ™¯**: è®­ç»ƒã€æ¨ç†ã€å›¾å½¢å·¥ä½œè´Ÿè½½
- **æ€§èƒ½**: æ¯” T4 é«˜ 2.5x
- **æ¨èç”¨é€”**: ä¸­ç­‰è§„æ¨¡è®­ç»ƒã€é«˜æ€§èƒ½æ¨ç†

| å®ä¾‹ç±»å‹ | GPU | vCPU | å†…å­˜ | ç½‘ç»œæ€§èƒ½ |
|---------|-----|------|------|----------|
| g5.xlarge | 1x A10G | 4 | 16 GB | æœ€é«˜ 10 Gbps |
| g5.2xlarge | 1x A10G | 8 | 32 GB | æœ€é«˜ 10 Gbps |
| g5.4xlarge | 1x A10G | 16 | 64 GB | æœ€é«˜ 25 Gbps |

### P3 ç³»åˆ— (NVIDIA V100)
- **é€‚ç”¨åœºæ™¯**: å¤§è§„æ¨¡è®­ç»ƒã€HPC
- **æ€§èƒ½**: æœ€é«˜
- **æ¨èç”¨é€”**: æ·±åº¦å­¦ä¹ è®­ç»ƒã€ç§‘å­¦è®¡ç®—

| å®ä¾‹ç±»å‹ | GPU | vCPU | å†…å­˜ | ç½‘ç»œæ€§èƒ½ |
|---------|-----|------|------|----------|
| p3.2xlarge | 1x V100 | 8 | 61 GB | æœ€é«˜ 10 Gbps |
| p3.8xlarge | 4x V100 | 32 | 244 GB | 10 Gbps |

## ğŸ’° æˆæœ¬ä¼˜åŒ–ç­–ç•¥

### Spot å®ä¾‹ä½¿ç”¨
```yaml
# åœ¨ NodePool ä¸­å¯ç”¨ Spot
requirements:
  - key: karpenter.sh/capacity-type
    operator: In
    values: ["spot"]  # ä»…ä½¿ç”¨ Spot å®ä¾‹
```

### è‡ªåŠ¨ç¼©å®¹é…ç½®
```yaml
# å¿«é€Ÿç¼©å®¹ä»¥èŠ‚çœæˆæœ¬
disruption:
  consolidationPolicy: WhenEmpty
  consolidateAfter: 30s  # 30ç§’åç¼©å®¹ç©ºé—²èŠ‚ç‚¹
```

### å®ä¾‹ç±»å‹ä¼˜å…ˆçº§
1. **å¼€å‘æµ‹è¯•**: g4dn.xlarge (Spot)
2. **ç”Ÿäº§æ¨ç†**: g5.xlarge (On-Demand)
3. **å¤§è§„æ¨¡è®­ç»ƒ**: p3.2xlarge (Spot + On-Demand æ··åˆ)

## ğŸ”§ æœºå™¨å­¦ä¹ å·¥ä½œè´Ÿè½½ç¤ºä¾‹

### PyTorch è®­ç»ƒä»»åŠ¡
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pytorch-training
spec:
  template:
    spec:
      containers:
      - name: pytorch
        image: pytorch/pytorch:latest
        resources:
          limits:
            nvidia.com/gpu: 1
          requests:
            nvidia.com/gpu: 1
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      nodeSelector:
        node-type: gpu
      restartPolicy: Never
```

### TensorFlow Serving
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tensorflow-serving
spec:
  replicas: 2
  selector:
    matchLabels:
      app: tensorflow-serving
  template:
    metadata:
      labels:
        app: tensorflow-serving
    spec:
      containers:
      - name: tensorflow-serving
        image: tensorflow/serving:latest-gpu
        resources:
          limits:
            nvidia.com/gpu: 1
          requests:
            nvidia.com/gpu: 1
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      nodeSelector:
        node-type: gpu
```

## ğŸ” ç›‘æ§å’Œæ•…éšœæ’é™¤

### æ£€æŸ¥ GPU èµ„æº
```bash
# æŸ¥çœ‹é›†ç¾¤ GPU èµ„æºæ€»é‡
kubectl describe nodes | grep -A 5 "Allocatable:" | grep nvidia.com/gpu

# æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ
kubectl top nodes --selector=node-type=gpu
```

### å¸¸è§é—®é¢˜

#### 1. GPU èŠ‚ç‚¹æ— æ³•å¯åŠ¨
**æ£€æŸ¥**:
```bash
# æŸ¥çœ‹èŠ‚ç‚¹äº‹ä»¶
kubectl describe node <gpu-node-name>

# æ£€æŸ¥ Karpenter æ—¥å¿—
kubectl logs -n karpenter deployment/karpenter
```

#### 2. Device Plugin æ— æ³•è¿è¡Œ
**æ£€æŸ¥**:
```bash
# æŸ¥çœ‹ Device Plugin æ—¥å¿—
kubectl logs -n kube-system -l name=nvidia-device-plugin-ds

# éªŒè¯ NVIDIA é©±åŠ¨
kubectl exec -it <gpu-pod> -- nvidia-smi
```

#### 3. Pod æ— æ³•è°ƒåº¦åˆ° GPU èŠ‚ç‚¹
**æ£€æŸ¥**:
```bash
# ç¡®è®¤ Toleration å’Œ NodeSelector
kubectl describe pod <gpu-pod>

# æ£€æŸ¥èŠ‚ç‚¹æ±¡ç‚¹
kubectl describe node <gpu-node> | grep Taints
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [AWS Deep Learning AMI](https://docs.aws.amazon.com/dlami/latest/devguide/what-is-dlami.html)
- [NVIDIA Device Plugin](https://github.com/NVIDIA/k8s-device-plugin)
- [Karpenter GPU æ”¯æŒ](https://karpenter.sh/docs/concepts/nodepools/)
- [EKS GPU å·¥ä½œè´Ÿè½½](https://docs.aws.amazon.com/eks/latest/userguide/gpu-ami.html)
