# GPU NodePool 配置
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: nodepool-gpu
spec:
  # 模板配置
  template:
    metadata:
      labels:
        node-type: gpu
        workload-type: ml
    spec:
      # 节点类别配置
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: nodeclass-gpu
      
      # 污点配置 - 确保只有 GPU 工作负载调度到这些节点
      taints:
        - key: nvidia.com/gpu
          value: "true"
          effect: NoSchedule
      
      # 资源要求
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot", "on-demand"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values: 
            # G4dn 系列 - NVIDIA T4 (x86_64) - 小模型推理
            - g4dn.xlarge    # 1x T4, 4 vCPU, 16 GB, 125GB NVMe
            - g4dn.2xlarge   # 1x T4, 8 vCPU, 32 GB, 225GB NVMe  
            - g4dn.4xlarge   # 1x T4, 16 vCPU, 64 GB, 225GB NVMe
            - g4dn.8xlarge   # 1x T4, 32 vCPU, 128 GB, 900GB NVMe
            - g4dn.12xlarge  # 4x T4, 48 vCPU, 192 GB, 900GB NVMe
            
            # G6 系列 - NVIDIA L4 (x86_64) - 高效推理
            - g6.xlarge      # 1x L4, 4 vCPU, 16 GB
            - g6.2xlarge     # 1x L4, 8 vCPU, 32 GB
            - g6.4xlarge     # 1x L4, 16 vCPU, 64 GB
            - g6.8xlarge     # 1x L4, 32 vCPU, 128 GB
            - g6.12xlarge    # 4x L4, 48 vCPU, 192 GB

            # G5g 系列 - NVIDIA T4g (ARM64) - 成本优化推理
            - g5g.xlarge     # 1x T4g, 4 vCPU, 8 GB
            - g5g.2xlarge    # 1x T4g, 8 vCPU, 16 GB
            - g5g.4xlarge    # 1x T4g, 16 vCPU, 32 GB
            - g5g.8xlarge    # 1x T4g, 32 vCPU, 64 GB
            - g5g.16xlarge   # 2x T4g, 64 vCPU, 128 GB
            
            # G5 系列 - NVIDIA A10G (x86_64) - 中大模型推理
            - g5.xlarge      # 1x A10G, 4 vCPU, 16 GB
            - g5.2xlarge     # 1x A10G, 8 vCPU, 32 GB
            - g5.4xlarge     # 1x A10G, 16 vCPU, 64 GB
            - g5.8xlarge     # 1x A10G, 32 vCPU, 128 GB
            - g5.12xlarge    # 4x A10G, 48 vCPU, 192 GB
            
            # G6e 系列 - NVIDIA L40S (x86_64) - 高性能推理
            - g6e.xlarge     # 1x L40S, 4 vCPU, 16 GB
            - g6e.2xlarge    # 1x L40S, 8 vCPU, 32 GB
            - g6e.4xlarge    # 1x L40S, 16 vCPU, 64 GB
            - g6e.8xlarge    # 1x L40S, 32 vCPU, 128 GB
            - g6e.12xlarge   # 4x L40S, 48 vCPU, 192 GB

        - key: kubernetes.io/arch
          operator: In
          values: ["amd64", "arm64"]  # 支持 x86_64 和 ARM64
  
  # 扩展限制
  limits:
    cpu: 1000
    memory: 1000Gi
  
  # 节点终止策略
  disruption:
    # 生产环境建议设为: WhenEmpty 以避免频繁迁移
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30m

---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: nodeclass-gpu
spec:
  # AMI 配置 - alias 模式自动选择 EKS-optimized AMI
  # Karpenter 会根据实例类型自动选 nvidia/standard AMI
  amiSelectorTerms:
    - alias: al2023@latest
  
  # 本地 NVMe 存储策略
  # AL2023 + RAID0: Karpenter 自动将所有 NVMe instance store 盘组 RAID0
  # 设备: /dev/md/0, 挂载点: /mnt/k8s-disks/0
  # 自动成为 kubelet ephemeral-storage，Pod 通过 emptyDir 即可使用 NVMe 高速存储
  instanceStorePolicy: RAID0
  
  # 安全组和子网
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: "eks-karpenter-env"
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "eks-karpenter-env"
  
  # IAM 角色
  role: "KarpenterNodeInstanceRole-eks-karpenter-env"

  metadataOptions:
    httpPutResponseHopLimit: 2    # 允许容器访问IMDS
    
  # 块设备映射 - 为 ML 工作负载提供足够存储
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 100Gi  # 持久化卷存储空间
        volumeType: gp3
        iops: 3000
        throughput: 125
        deleteOnTermination: true
