apiVersion: apps/v1
kind: Deployment
metadata:
  name: qwen3-tts-base
  namespace: hosthree
  labels:
    app: qwen3-tts-base
spec:
  replicas: 1
  selector:
    matchLabels:
      app: qwen3-tts-base
  template:
    metadata:
      labels:
        app: qwen3-tts-base
    spec:
      initContainers:
      - name: model-downloader
        image: 123456789012.dkr.ecr.us-west-2.amazonaws.com/qwen3-tts:latest
        securityContext:
          runAsUser: 0
        command:
        - bash
        - -c
        - |
          MODEL_DIR="/models/Qwen3-TTS-Base"
          if ls "$MODEL_DIR"/*.safetensors 1>/dev/null 2>&1 && [ -f "$MODEL_DIR/config.json" ]; then
            echo "Model complete, skipping download"
          else
            echo "Model incomplete or missing, downloading..."
            rm -rf "$MODEL_DIR"
            huggingface-cli download Qwen/Qwen3-TTS-12Hz-1.7B-Base --local-dir "$MODEL_DIR"
          fi
        volumeMounts:
        - name: models
          mountPath: /models
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 1
            memory: 4Gi

      containers:
      - name: tts
        image: 123456789012.dkr.ecr.us-west-2.amazonaws.com/qwen3-tts:latest
        env:
        - name: TTS_BACKEND
          value: "official"
        - name: TTS_MODEL_ID
          value: "/models/Qwen3-TTS-Base"
        - name: TTS_DEVICE
          value: "auto"
        - name: TTS_DTYPE
          value: "bfloat16"
        - name: TTS_ATTN
          value: "flash_attention_2"
        - name: HOST
          value: "0.0.0.0"
        - name: PORT
          value: "8860"
        - name: TTS_WARMUP_ON_START
          value: "true"
        ports:
        - containerPort: 8860
          name: http
        volumeMounts:
        - name: models
          mountPath: /models
          readOnly: true
        resources:
          requests:
            cpu: 500m
            memory: 3Gi
            nvidia.com/gpu: 1
          limits:
            cpu: "2"
            memory: 8Gi
            nvidia.com/gpu: 1
        startupProbe:
          httpGet:
            path: /health
            port: 8860
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 30
        livenessProbe:
          tcpSocket:
            port: 8860
          periodSeconds: 30
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 8860
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3

      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: qwen3-models-pvc

      tolerations:
      - key: nvidia.com/gpu
        operator: Equal
        value: "true"
        effect: NoSchedule
      nodeSelector:
        node-type: gpu
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            preference:
              matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values: ["g6.xlarge", "g6.2xlarge", "g6.4xlarge"]
          - weight: 30
            preference:
              matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values: ["g5.xlarge", "g5.2xlarge", "g5.4xlarge"]
          - weight: 20
            preference:
              matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values: ["g4dn.xlarge", "g4dn.2xlarge", "g4dn.4xlarge"]

      restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: qwen3-tts-base-service
  namespace: hosthree
  labels:
    app: qwen3-tts-base
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8860
    protocol: TCP
    name: http
  selector:
    app: qwen3-tts-base
